# ğŸ“˜ Documentazione Applicazione FastAPI

Questa applicazione Ã¨ costruita con **FastAPI** e si basa su container **Docker** e su un database **MongoDB**.  
Gli endpoint sono definiti allâ€™interno del modulo `app/api.py` e utilizzano varie classi e funzioni di supporto presenti nella directory `utilities`.

---

## ğŸš€ Requisiti

Prima di avviare lâ€™applicazione, Ã¨ necessario avere installato:

- [Docker Desktop](https://www.docker.com/products/docker-desktop/)  
- [MongoDB](https://www.mongodb.com/try/download/community)

---

## â–¶ï¸ Avvio dellâ€™applicazione

1. Clona il repository sul tuo sistema:
   ```bash
   git clone <URL_REPOSITORY>
   cd <NOME_DIRECTORY>
```

2. Assicurati che **Docker Desktop** e **MongoDB** siano in esecuzione.

3. Esegui il comando per avviare i container:

```bash
   docker compose up -d --build
```

   Questo comando:

   * installerÃ  tutte le dipendenze specificate in `requirements.txt`;
   * avvierÃ  lâ€™applicazione eseguendo automaticamente:

     ```bash
     python -m uvicorn app.api:app --host 0.0.0.0 --port 8091
     ```

4. Una volta avviata, lâ€™applicazione sarÃ  accessibile su:
   ğŸ‘‰ [http://localhost:8091](http://localhost:8091)

---

## ğŸ“‚ Struttura del progetto

```
LEONARDO_RAG
â”œâ”€â”€ .venv/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â””â”€â”€ api.py
â”œâ”€â”€ input_data/
â”œâ”€â”€ tests/
â”œâ”€â”€ utilities/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ img_out/
â”‚   â”œâ”€â”€ retrieved_images/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ dataloader.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ mongodb.py
â”‚   â””â”€â”€ retrieving.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ TODO.md
```

---

## ğŸ”— Endpoints (modulo `app/api.py`)

Gli endpoint dellâ€™applicazione sono definiti in `app/api.py`.
Al loro interno vengono utilizzate funzioni di supporto e classi definite nei vari moduli della directory `utilities`.

ğŸ‘‰ La spiegazione dei singoli endpoint, insieme ai metodi e alle classi di supporto, verrÃ  fornita **man mano** che intercorrono negli endpoints.

---

## ğŸ› ï¸ Utilities

La directory `utilities` contiene i moduli di supporto che forniscono classi e metodi fondamentali per il funzionamento degli endpoint.
Alcuni esempi:

* **`mongodb.py`** â†’ Gestione connessioni e query su MongoDB.
* **`dataloader.py`** â†’ Parsing e caricamento di documenti (PDF, immagini, ecc.).
* **`chunking.py`** â†’ Gestione e suddivisione dei testi in blocchi semantici.
* **`embeddings.py`** â†’ Creazione e utilizzo di embeddings per modelli AI.
* **`retrieving.py`** â†’ Funzioni di retrieval da database o documenti esterni.

---

## ğŸ“– Come funziona

1. **Richiesta API** â†’ un client invia la richiesta a uno degli endpoint di `api.py`.
2. **Elaborazione** â†’ lâ€™endpoint richiama funzioni e classi definite in `utilities`.
3. **Accesso ai dati** â†’ tramite `MongoDBToolKitManager` o altri moduli, i dati vengono letti/salvati nel database.
4. **Risposta** â†’ lâ€™API restituisce un output JSON al client.

---

## ğŸ“š Documentazione per gli Endpoint


# ğŸ§­ Panoramica

Questa sezione:

1. carica le variabili dâ€™ambiente,
2. definisce un **lifespan asincrono** per inizializzare (e rilasciare) il modello di embedding una sola volta,
3. crea lâ€™istanza FastAPI, un router, le cartelle di lavoro, e i **manager** (Documenti, MongoDB, Qdrant).

# ğŸ” Variabili dâ€™ambiente

```python
from dotenv import load_dotenv
load_dotenv()
```

Carica dal file `.env` valori come **HF\_TOKEN** per autenticarsi su HuggingFace o altri segreti (es. credenziali DB).
âœ… Verifica: il file `.env` Ã¨ presente e non viene committato (Ã¨ in `.gitignore`).

---

# âš™ï¸ Lifespan asincrono (setup/teardown dellâ€™app)

```python
model = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global model
    print("Caricamento del modello Jina Emebddings...")
    hf_token=os.getenv("HF_TOKEN")
    model = get_embedding_model(hf_token)
    print("âœ”ï¸ Modello caricato")
    yield
    # eventualmente cleanup
    model = None
```

## Cosâ€™Ã¨ e perchÃ© usarlo

* `@asynccontextmanager` definisce un **context manager asincrono** usato da FastAPI come **ciclo di vita** dellâ€™app.
* Esegue il **setup una sola volta allâ€™avvio** (bootstrap) e il **cleanup alla chiusura**.

## Cosa inizializza

* Carica il **modello di embedding** (Jina) tramite `get_embedding_model(hf_token)`.
* Lo salva in una **variabile globale `model`** per riutilizzarlo negli endpoint senza ricaricarlo ad ogni richiesta (risparmio enorme di tempo e memoria).

## Note operative

* Se il token HF non Ã¨ valido o mancante â†’ solleverÃ  un errore in avvio.
  ğŸ‘‰ Consiglio: gestire eccezioni e loggare un messaggio chiaro.
* `model = None` nel teardown libera memoria alla chiusura del server.

---

# ğŸ Istanza FastAPI e Router

```python
app = FastAPI(lifespan=lifespan)
router = APIRouter()
```

* Lâ€™app FastAPI usa il **lifespan** definito sopra.
* `router` verrÃ  usato per raggruppare gli endpoint (es. `@router.post(...)`) e poi **incluso** nellâ€™app (`app.include_router(router, prefix="...")`) piÃ¹ avanti nel file.

---

# ğŸ“‚ Path di lavoro (upload) e manager applicativi

```python
UPLOAD_FOLDER = Path(__file__).resolve().parent.parent / "input_data"
UPLOAD_FOLDER.mkdir(exist_ok=True)
```

* Crea (se non esiste) `input_data/` **alla radice del progetto** (stessa struttura della tua repo).
* Qui verranno salvati i PDF o file caricati via API (`UploadFile`).

```python
doc_manager = DocumentManager()
mongo_manager = MongoManager(connection_string="mongodb://host.docker.internal:27017")
```

* `DocumentManager` â†’ lettura, parsing, conversione documenti (PDF, immagini, ecc.).
* `MongoManager` â†’ wrapper per collegarsi a **MongoDB**.

ğŸ’¡ **PerchÃ© `host.docker.internal`?**
Allâ€™interno del **container Docker**, questo hostname punta alla macchina host.

* Se MongoDB gira **sul tuo host** (non in Docker), questo Ã¨ lâ€™endpoint corretto.
* Se invece MongoDB gira **in un container** nello stesso compose, conviene usare il **service name** definito in `docker-compose.yml` (es. `mongodb:27017`).

```python
client = QdrantClient(url="http://qdrant:6333")
```

* Crea la connessione a **Qdrant** (vector DB) tramite lâ€™URL del **service name** `qdrant` esposto sulla porta `6333` (tipico in Docker Compose).
* VerrÃ  usato per **indicizzare e cercare** embeddings (similarity / ANN search).

---

# ğŸ§© Come interagiscono questi pezzi (in pratica)

1. **Avvio server** â†’ `lifespan` carica **una volta** il modello di embedding Jina (usando `HF_TOKEN`).
2. **Richiesta API** â†’ un endpoint (definito piÃ¹ avanti) usa:

   * `DocumentManager` per leggere/convertire documenti,
   * `JinaEmbeddings`/`model` per calcolare vettori,
   * `QdrantClient` per upsert/search,
   * `MongoManager` per salvare/mettere a disposizione metadati o risultati.
3. **Risposta** â†’ JSON formattato con Pydantic.

---

# ğŸ“š Endpoints definiti in `app/api.py`

Tutti gli endpoint sono accessibili con il prefisso `/leonardo`.

---

# ğŸ”¹ Endpoint: `POST /upload-and-parse-pdf/`

* **Cosa fa**:
  Riceve un file PDF, lo salva in `input_data/`, ne estrae il testo in formato Markdown tramite `DocumentManager`, e genera un nuovo file `.md` con il contenuto estratto.
  Restituisce JSON con nome file, percorso salvato, percorso del `.md` e unâ€™anteprima del testo.

* **Dove salva**:

  * PDF caricato â†’ `input_data/`
  * File `.md` estratto â†’ `input_data/<nome>.md`
  * Immagini del PDF (se presenti) â†’ `utilities/img_out/`

# ğŸ“¦ Classe `DocumentManager`

Contiene i metodi usati dallâ€™endpoint per gestire i documenti.

* **`read_local_pdf(file_path)`**
  Legge un PDF locale con PyMuPDF + pymupdf4llm, estrae testo in Markdown e salva eventuali immagini in `utilities/img_out/`.

* **`create_local_document(file_name, content)`**
  Crea un nuovo file di testo/Markdown in `input_data/` con il contenuto fornito.

* **`convert_images_to_base64(image_dir, img_ext="png")`**
  Converte immagini in base64 e le cancella dopo la conversione. Restituisce lista di dizionari con id, filename e contenuto base64.

* **`save_base64_to_image(base64_str, filename)`**
  Decodifica una stringa base64 e salva lâ€™immagine in `input_data/`.

---

# ğŸ”¹ Endpoint: `POST /upload-images-to-mongo`

* **Cosa fa**
  Legge tutte le immagini presenti in `utilities/img_out/`, le converte in **base64** e le inserisce in **MongoDB** nella **db `Leonardo`**, **collection `images`**.
  Se trova in collection immagini con lo **stesso `filename`** del batch corrente, **non reinserisce** e avvisa che sono giÃ  presenti.

* **Dove prende/salva i dati**

  * **Input immagini**: `utilities/img_out/`
  * **DB di destinazione**: MongoDB â†’ `Leonardo.images`
  * **Nota**: durante la conversione, i file in `img_out/` vengono **cancellati** (comportamento di `convert_images_to_base64`).

* **Passi principali**

  1. Costruisce il path `img_out/`.
  2. `DocumentManager.convert_images_to_base64(...)` â†’ lista di `{image_id, filename, content_base64, timestamp}` e **rimozione file originali**.
  3. Usa `MongoManager._get_collection("Leonardo", "images")`.
  4. **Dedup**: verifica se esistono giÃ  documenti con lo **stesso `filename`** del primo elemento del batch.
  5. Se non esistono, inserisce tutta la lista con `MongoManager.write_to_mongo(...)`.
  6. Risponde con conteggio inseriti o messaggio â€œnessuna immagine trovataâ€.

# ğŸ“¦ Classi e metodi coinvolti

## `DocumentManager` (da `utilities/dataloader.py`)

* **`convert_images_to_base64(image_dir, img_ext="png")`**
  Converte tutte le immagini della cartella in **base64**, produce una lista di dict (id, filename, contenuto, timestamp) e **cancella i file** sorgente dopo la conversione.

## `MongoManager` (da `utilities/mongodb.py`)

* **`_get_collection(database_name, collection_name)`**
  Restituisce lâ€™oggetto collection (`Leonardo.images` in questo endpoint).
* **`write_to_mongo(data, database_name, collection_name)`**
  Inserisce un **dict** o una **lista di dict** (qui: la lista delle immagini base64).
* *(usato inline)* `collection.find({"filename": filename})` per controllo duplicati.

---

Ecco la versione sintetica per il **terzo endpoint** e le utility usate.

---

# ğŸ”¹ Endpoint: `POST /chunking`

* **Cosa fa**
  Riceve un file **Markdown (.md)**, verifica che esista il **PDF omonimo** in `input_data/`, sceglie **chunk\_size/overlap** in base al **numero di pagine** del PDF, segmenta il testo in **chunk semantici**, li trasforma in `Document` (con metadati), e salva tutto in **MongoDB** (`Leonardo.documents`). Evita doppi inserimenti se il `filename` Ã¨ giÃ  presente.

* **Dove legge/salva**

  * Input: file `.md` (upload); PDF atteso in `input_data/<nome>.pdf`
  * Output su Mongo: DB **Leonardo**, collection **documents**
  * Risposta: anteprima (primi 10) + conteggio totale

* **Passi principali**

  1. **Validazione** estensione `.md` e **presenza PDF** omonimo in `input_data/`.
  2. **Conta pagine** PDF (pypdf) â†’ imposta dinamicamente `chunk_size/overlap`.
  3. **Dedup** su Mongo (`Leonardo.documents`) per `filename`.
  4. **Split** markdown (`split_markdown_text`).
  5. **Create** `Document` (`create_documents`) con:

     * contenuto pulito,
     * metadata: `chunk_no`, `images` (link immagine estratti).
  6. **Persistenza** su Mongo con `mongo_manager.write_to_mongo`.
  7. **Response**: `total_chunks`, `chunks` (prime 10 stringhe), `docs` (prime 10 serializzate senza `_id/file_id`).


# ğŸ“¦ Utility coinvolte (da `utilities/chunking.py`)

* **`split_markdown_text(text, chunk_size, chunk_overlap)`**
  Split ricorsivo con `RecursiveCharacterTextSplitter` usando separatori markdown (titoli, paragrafi, righe, parole) per chunk **coesi**.

* **`clean_markdown(text)`**
  Normalizza: rimuove titoli/markup **markdown** superfluo, caratteri di controllo, righe vuote multiple, simboli non informativi.

* **`create_documents(chunks)`**
  Per ogni chunk:

  * estrae link immagini `![](...)` â†’ li mette in `metadata["images"]`,
  * rimuove i link dal testo,
  * applica `clean_markdown`,
  * crea `Document(page_content, metadata={"chunk_no": i, "images": [...]})`.


# ğŸ—ƒï¸ MongoDB (da `utilities/mongodb.py`)

* **`_get_collection("Leonardo", "documents")`** per la collection.
* **`write_to_mongo(data, "Leonardo", "documents")`** salva lista di documenti.
* Query **dedup**: `collection.find({"filename": file.filename})`.


# ğŸ§¾ Output (esempio)

```json
{
  "total_chunks": 128,
  "chunks": ["<chunk_0>", "..."],
  "docs": [
    {
      "filename": "report.md",
      "document_id": "uuid",
      "page_content": "<testo pulito>",
      "metadata": {"chunk_no": 0, "images": ["utilities/img_out/p1_01.png"]},
      "uploaded_at": "2025-09-09T08:30:00.000000"
    }
  ]
}
```

**Nota:** il PDF deve trovarsi in `input_data/` con lo **stesso nome** del `.md` (es. `report.md` â†” `report.pdf`) per stimare i parametri di chunking.


---

# ğŸ”¹ Endpoint: `POST /embeddings`

* **Cosa fa**
  Per un dato `file_name`:

  1. legge da **MongoDB â†’ Leonardo.documents** tutti i chunk (`page_content`, `metadata`) con `filename = file_name`;
  2. calcola gli **embedding testo** dei `page_content` tramite **JinaEmbeddings** (modello giÃ  caricato nel `lifespan`);
  3. crea/usa in **Qdrant** la collection `hitachi` (distance **COSINE**) con **dimensionalitÃ ** = len(embedding);
  4. fa **upsert** dei punti in Qdrant con `payload = metadata` (+ `filename`), 1 punto per chunk.

* **Dove legge/salva**

  * **Lettura**: MongoDB â†’ DB `Leonardo`, collection `documents`
  * **Scrittura**: Qdrant â†’ collection `hitachi`
  * **Vettori**: dimensione determinata dal modello (es. 2048 per `jina-embeddings-v4`)

* **Output**

  ```json
  {
    "message": "<N> embeddings con dimensionalitÃ  <D> sono stati inseriti correttamente nella collection",
    "collection_name": "hitachi",
    "vector_size": <D>
  }
  ```

* **Note operative**

  * Lâ€™upsert usa **UUID nuovi** per ogni chunk â†’ non sovrascrive inserimenti precedenti dello stesso file (no dedup naturale a meno di gestire ID stabili).
  * `metadata` include almeno `chunk_no` e `filename`.

---

# ğŸ“¦ Utility coinvolte (da `utilities/embeddings.py`)

## `JinaEmbeddings`

Wrapper compatibile LangChain per il modello Jina (testo/immagini).

* **`embed_documents(texts: list[str]) -> list[list[float]]`**
  Embedding **batch** di testi per **retrieval** (`prompt_name="passage"`).
* **`embed_query(text: str) -> list[float]`**
  Embedding di **query** (`prompt_name="query"`).
* **`embed_images(image_paths: list[str]) -> list[list[float]]`**
  Embedding immagini (non usato in questo endpoint).

## `get_embedding_model(token: str)`

Carica **`jinaai/jina-embeddings-v4`** (Hugging Face) con `trust_remote_code=True`, su **CUDA** se disponibile, altrimenti CPU.
Ritorna lâ€™oggetto modello usato da `JinaEmbeddings`.

---

# ğŸ—ƒï¸ Mongo & Qdrant

* **MongoManager**

  * `read_from_mongo(query={"filename": file_name}, output_format="object", db="Leonardo", coll="documents")` â†’ recupero chunk e metadati.

* **QdrantClient**

  * `collection_exists` / `create_collection(VectorParams(size=D, distance=COSINE))`
  * `upsert(points=[PointStruct(id=uuid4, vector=embedding, payload=metadata)])`

---

# ğŸ” Flusso minimo

`Mongo (chunks) â†’ JinaEmbeddings(embed_documents) â†’ Qdrant(create_collection if needed) â†’ upsert(points)`


---

# ğŸ”¹ Endpoint: `POST /retriever`

* **Cosa fa**
  Dato `file_name` e una `query`:

  1. filtra in **Qdrant** i vettori del solo documento (`Filter` su `filename`),
  2. calcola lâ€™embedding della query con **JinaEmbeddings** e recupera i **top-5** chunk piÃ¹ simili,
  3. ricostruisce il **contesto** testuale dai chunk salvati in **MongoDB** e raccoglie le **immagini** associate,
  4. invoca un **LLM locale** (Ollama `llama3.1:8b`) con prompt *context-aware* per generare la risposta,
  5. scarica da Mongo le immagini correlate (base64) e le **salva su disco** per la risposta.

* **Dove legge/salva**

  * **Vettori**: Qdrant â†’ collection `hitachi` (filtrata per `filename`)
  * **Chunk & immagini (base64)**: MongoDB â†’ `Leonardo.documents` e `Leonardo.images`
  * **Salvataggio immagini decodificate**: `utilities/retrieved_images/`
  * **LLM**: Ollama su `http://host.docker.internal:11434`

* **Output**

  ```json
  {
    "answer": "<risposta LLM basata sul contesto>",
    "images": ["utilities/retrieved_images/img1.png", "..."]
  }
  ```

# ğŸ§© Passi principali

1. **Filtro per documento**

   ```python
   query_filter = Filter(must=[FieldCondition(key="filename", match=MatchValue(value=file_name))])
   ```

   Limita la ricerca ai soli vettori del file.

2. **Prompt & LLM**

   * Prompt `ChatPromptTemplate`: â€œAnswer the question based only on the following context: {context} â€¦â€
   * LLM: `ChatOllama(model="llama3.1:8b", temperature=0.2)`

3. **Pipeline LangChain**

   * `retriever_ji_full`: `RunnableLambda` che chiama il **retriever** e restituisce `(context, images, query)`
   * `split`: `RunnableMap` per comporre il dict `{context, images, question}`
   * `chain_model`: `prompt | llm | StrOutputParser()`
   * `full_chain`: esegue retrieve â†’ genera `answer` â†’ ritorna `{"answer", "images"}`

4. **Download immagini**

   * Per ciascun `image_name` recuperato dal contesto:

     * legge `content_base64` da `Leonardo.images`
     * decodifica e salva in `utilities/retrieved_images/`
     * accumula i path salvati per la risposta


# ğŸ“¦ Utility coinvolte

## `retriever_jina(query: str, model: AutoModel, query_filter: Filter)`

* Embedding **query** con `JinaEmbeddings.embed_query`.
* `QdrantClient.query_points(...)` con `SearchParams(hnsw_ef=128, exact=False)`, `limit=5`, `with_payload=True`.
* Per ogni match:

  * legge da Mongo `Leonardo.documents` il `page_content` e `metadata.images` corrispondenti a `chunk_no` e `filename`.
* Ritorna:

  * `full_content` = join dei contenuti chunk,
  * `full_images` = lista piatta delle immagini collegate.

## `MongoManager`

* `read_from_mongo(...)` per:

  * `documents`: ricostruire il contesto testuale e recuperare `images`
  * `images`: ottenere `content_base64` per il salvataggio su disco

# ğŸ” Flusso minimo

`query â†’ embed_query â†’ Qdrant (filter by filename) â†’ top-5 chunk â†’ Mongo (contenuti + immagini) â†’ LLM con context â†’ decodifica immagini da Mongo â†’ salva in utilities/retrieved_images â†’ {"answer", "images"}`

---

# Esempio di flusso di esecuzione 

Ecco un esempio di**flusso end-to-end** di tutti gli endpoint, in ordine, con **input e output di esempio**.

---

# 1) Carica PDF â†’ estrai testo + immagini

`POST /upload-and-parse-pdf/`

```bash
curl -X POST http://localhost:8091/upload-and-parse-pdf/ \
  -H "accept: application/json" \
  -F "file=@/path/Report_Tech.pdf"
```

**Effetti**

* Salva il PDF in `input_data/Report_Tech.pdf`
* Estrae testo â†’ salva `input_data/Report_Tech.md`
* Estrae immagini â†’ salva in `utilities/img_out/` (png)

**Output (esempio)**

```json
{
  "filename": "Report_Tech.pdf",
  "file_path": "/app/input_data/Report_Tech.pdf",
  "new_md_file": "/app/input_data/Report_Tech.md",
  "parsed_text": "# Executive Summary...\n(anteprima 500 char)"
}
```

---

# 2) Carica immagini estratte in MongoDB

`POST /upload-images-to-mongo`

```bash
curl -X POST http://localhost:8091/upload-images-to-mongo \
  -H "accept: application/json"
```

**Effetti**

* Legge `utilities/img_out/*.png`
* Converte in base64 e **inserisce** in `MongoDB â†’ Leonardo.images`
* (Le immagini locali vengono **cancellate** dopo la conversione)

**Output (esempio)**

```json
{
  "inserted_count": 7,
  "message": "7 images successfully inserted to mongoDB"
}
```

*(Se giÃ  presenti per lo stesso filename: `{"message":"Immagini dello stesso file p1_01.png giÃ  presenti in MongoDB"}`)*

---

# 3) Chunking del Markdown â†’ salvataggio su Mongo

`POST /chunking`

> âš ï¸ Richiede che esista il **PDF omonimo** in `input_data/` (es. `Report_Tech.pdf`).

```bash
curl -X POST http://localhost:8091/chunking \
  -H "accept: application/json" \
  -F "file=@/path/Report_Tech.md"
```

**Effetti**

* Calcola `chunk_size/overlap` in base alle **pagine del PDF**
* Segmenta testo â†’ crea `Document` con `metadata={chunk_no, images}`
* Inserisce tutto in `MongoDB â†’ Leonardo.documents`

**Output (esempio)**

```json
{
  "total_chunks": 124,
  "chunks": [
    "Introduzione\nIl presente documento...",
    "Specifiche tecniche principali...",
    "... (fino a 10 anteprime) ..."
  ],
  "docs": [
    {
      "filename": "Report_Tech.md",
      "document_id": "f8f6c1a1-7a16-4a1f-92a2-3a8f2d2a8c21",
      "page_content": "Introduzione Il presente documento...",
      "metadata": { "chunk_no": 0, "images": ["utilities/img_out/p1_01.png"] },
      "uploaded_at": "2025-09-09T08:30:00.000000"
    }
  ]
}
```

---

# 4) Embeddings â†’ upsert su Qdrant

`POST /embeddings`

```bash
curl -X POST "http://localhost:8091/embeddings?file_name=Report_Tech.md" \
  -H "accept: application/json"
```

**Effetti**

* Legge i chunk da `Leonardo.documents` (filtrati per `filename`)
* Calcola embeddings testo con **JinaEmbeddings**
* Crea (se serve) la collection `hitachi` (distance COSINE, dim es. 2048)
* **Upsert** dei vettori con payload = metadata + filename

**Output (esempio)**

```json
{
  "message": "124 embeddings con dimensionalitÃ  2048 sono stati inseriti correttamente nella collection",
  "collection_name": "hitachi",
  "vector_size": 2048
}
```

---

# 5) Retrieval + Answering + salvataggio immagini correlate

`POST /retriever`

```bash
curl -X POST "http://localhost:8091/retriever?file_name=Report_Tech.md&query=Quali sono le specifiche della pompa idraulica?" \
  -H "accept: application/json"
```

**Effetti**

* Filtra in Qdrant per `filename=Report_Tech.md`, `top-5` chunk simili
* Ricostruisce **context** dai chunk in `Leonardo.documents`
* Invoca **Ollama** (`llama3.1:8b`) con prompt basato sul solo **context**
* Recupera immagini collegate da `Leonardo.images` (base64) â†’ **salva file** in `utilities/retrieved_images/`

**Output (esempio)**

```json
{
  "answer": "La pompa idraulica Ã¨ di tipo a palette con portata nominale 45 l/min a 3000 rpm, pressione massima 210 bar, efficienza volumetrica 92%.",
  "images": [
    "utilities/retrieved_images/p1_01.png",
    "utilities/retrieved_images/p2_03.png"
  ]
}
```

---

## ğŸ§­ Riassunto rapido del flusso

1. **PDF â†’ md + immagini**
   `/upload-and-parse-pdf/` â†’ `input_data/Report_Tech.md` + `utilities/img_out/*.png`
2. **Immagini â†’ Mongo (base64)**
   `/upload-images-to-mongo` â†’ `Leonardo.images`
3. **Chunk md â†’ Mongo**
   `/chunking` â†’ `Leonardo.documents` (Document per chunk)
4. **Embeddings â†’ Qdrant**
   `/embeddings` â†’ `hitachi` (vettori + payload)
5. **Query â†’ Retrieve + LLM + immagini salvate**
   `/retriever` â†’ risposta + `utilities/retrieved_images/*.png`

---

## ğŸ› ï¸ Tecnologie utilizzate

* **FastAPI**: per il backend API
* **MongoDB**: storage documentale
* **Qdrant**: vector store per embeddings
* **Jina Embeddings v4**: modello per la vettorializzazione
* **LangChain**: orchestrazione di componenti AI
* **Ollama**: serving locale del modello `qwen2.5:7b`
* **PyMuPDF / PIL / pypdf**: parsing PDF e immagini
